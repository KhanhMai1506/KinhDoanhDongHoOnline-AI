from fastapi import FastAPI, Request, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from fastapi.security import HTTPBearer
from pydantic import BaseModel, Field
from rag_chain import create_qa_chain
from typing import Dict, Optional, List, Any
import re
import uuid
import logging
import time
from datetime import datetime, timedelta
from collections import defaultdict
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('chatbot.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="Smart Watch Chatbot API",
    description="AI-powered chatbot for watch consultation with context memory",
    version="1.0.0"
)

# Security
security = HTTPBearer(auto_error=False)

# Rate limiting
request_counts = defaultdict(list)
MAX_REQUESTS_PER_MINUTE = int(os.getenv("MAX_REQUESTS_PER_MINUTE", "60"))

# Kh·ªüi t·∫°o QA chain
try:
    qa_chain = create_qa_chain()
    llm = qa_chain["llm"]
    prompt = qa_chain["prompt"]
    vectordb = qa_chain["vectordb"]
    logger.info("QA chain initialized successfully")
except Exception as e:
    logger.error(f"Failed to initialize QA chain: {e}")
    raise

# L∆∞u tr·ªØ ng·ªØ c·∫£nh theo session v·ªõi c·∫£i ti·∫øn
session_contexts: Dict[str, Dict] = {}
conversation_history: Dict[str, List[Dict]] = {}

# C·∫•u h√¨nh CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=os.getenv("ALLOWED_ORIGINS", "http://localhost:5173,http://localhost:8001").split(","),
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class ChatRequest(BaseModel):
    question: str = Field(..., min_length=1, max_length=500, description="C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng")
    session_id: Optional[str] = Field(None, description="ID session ƒë·ªÉ duy tr√¨ ng·ªØ c·∫£nh")
    user_id: Optional[str] = Field(None, description="ID ng∆∞·ªùi d√πng (t√πy ch·ªçn)")


class ChatResponse(BaseModel):
    session_id: str
    response: str
    context_info: Optional[Dict] = None


def validate_input(question: str) -> str:
    """Validate v√† sanitize input"""
    if not question or not question.strip():
        raise HTTPException(status_code=400, detail="C√¢u h·ªèi kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng")
    
    question = question.strip()
    if len(question) > 500:
        raise HTTPException(status_code=400, detail="C√¢u h·ªèi qu√° d√†i (t·ªëi ƒëa 500 k√Ω t·ª±)")
    
    # Basic sanitization
    question = re.sub(r'<script.*?</script>', '', question, flags=re.IGNORECASE)
    return question


def check_rate_limit(session_id: str) -> bool:
    """Ki·ªÉm tra rate limit"""
    now = time.time()
    minute_ago = now - 60
    
    # Clean old requests
    request_counts[session_id] = [req_time for req_time in request_counts[session_id] if req_time > minute_ago]
    
    # Check limit
    if len(request_counts[session_id]) >= MAX_REQUESTS_PER_MINUTE:
        return False
    
    request_counts[session_id].append(now)
    return True


def is_relevant_question(question: str) -> bool:
    """Ki·ªÉm tra c√¢u h·ªèi li√™n quan v·ªõi c·∫£i ti·∫øn"""
    question = question.lower().strip()
    
    # T·ª´ kh√≥a v·ªÅ ƒë·ªìng h·ªì, th∆∞∆°ng hi·ªáu, th√¥ng tin chung
    keywords = [
        'ƒë·ªìng h·ªì', 'watch', 's·∫£n ph·∫©m', 'm·∫´u m√£', 'h√†ng', 'mua', 'b√°n',
        'casio', 'seiko', 'citizen', 'orient', 'tissot', 'omega', 'rolex',
        'gi√°', 'gi√° c·∫£', 'bao nhi√™u ti·ªÅn', 'ƒë·∫∑c ƒëi·ªÉm', 't√≠nh nƒÉng',
        'b·∫£o h√†nh', 'ch√≠nh h√£ng', 'ƒëeo tay', 'th∆∞∆°ng hi·ªáu', 'lo·∫°i',
        'li√™n h·ªá', 'ch√≠nh s√°ch', 'ƒë·ªïi tr·∫£', 'thanh to√°n', 'tr·∫£ g√≥p',
        'ƒë·ªãa ch·ªâ', 's·ªë ƒëi·ªán tho·∫°i', 'h·ªó tr·ª£', 'showroom', 'hotline', 'contact',
        't∆∞ v·∫•n', 'gi·ªõi thi·ªáu', 'so s√°nh', 'khuy·∫øn m√£i', 'gi·∫£m gi√°',
        'giao h√†ng', 'ship', 'v·∫≠n chuy·ªÉn'
    ]
    
    brands = ['casio', 'seiko', 'citizen', 'orient', 'tissot', 'omega', 'rolex']
    
    # N·∫øu c√¢u h·ªèi ch·ªâ l√† t√™n th∆∞∆°ng hi·ªáu
    if question in brands:
        return True
    
    # Ki·ªÉm tra t·ª´ kh√≥a
    return any(keyword in question for keyword in keywords)


def detect_specific_model(question: str) -> Optional[str]:
    """Ph√°t hi·ªán xem c√¢u h·ªèi c√≥ ch·ª©a model c·ª• th·ªÉ kh√¥ng"""
    # Pattern: Brand + Code (e.g., Casio MTP-1374L)
    brands = ['casio', 'seiko', 'citizen', 'orient', 'tissot', 'omega', 'rolex', 'doxa', 'saga']
    for brand in brands:
        if brand in question.lower():
            # T√¨m t·ª´ ngay sau brand
            match = re.search(fr"{brand}\s+([A-Za-z0-9\-]+)", question, re.IGNORECASE)
            if match:
                code = match.group(1)
                # N·∫øu code c√≥ s·ªë HO·∫∂C c√≥ d·∫•u g·∫°ch ngang, kh·∫£ nƒÉng cao l√† model
                if any(c.isdigit() for c in code) or "-" in code:
                    return code
    return None


def extract_search_filters(question: str) -> Dict[str, Any]:
    """Tr√≠ch xu·∫•t b·ªô l·ªçc t·ª´ c√¢u h·ªèi"""
    filters = {}
    question_lower = question.lower()
    
    # L·ªçc theo gi·ªõi t√≠nh
    if "nam" in question_lower and "n·ªØ" not in question_lower:
        filters["gender"] = "nam"
    elif "n·ªØ" in question_lower and "nam" not in question_lower:
        filters["gender"] = "nu"
        
    # L·ªçc theo gi√°
    # D∆∞·ªõi X tri·ªáu
    under_match = re.search(r"d∆∞·ªõi\s+(\d+)\s*(tri·ªáu|tr|m)", question_lower)
    if under_match:
        amount = int(under_match.group(1)) * 1000000
        filters["price"] = {"$lt": amount}
        
    # Tr√™n X tri·ªáu
    over_match = re.search(r"(tr√™n|h∆°n)\s+(\d+)\s*(tri·ªáu|tr|m)", question_lower)
    if over_match:
        amount = int(over_match.group(2)) * 1000000
        filters["price"] = {"$gt": amount}
        
    # Kho·∫£ng X-Y tri·ªáu
    range_match = re.search(r"t·ª´\s+(\d+)\s*-\s*(\d+)\s*(tri·ªáu|tr|m)", question_lower)
    if range_match:
        min_amount = int(range_match.group(1)) * 1000000
        max_amount = int(range_match.group(2)) * 1000000
        # Chroma c·∫ßn t√°ch ri√™ng c√°c ƒëi·ªÅu ki·ªán
        if "$and" not in filters:
             filters["$and"] = []
        filters["$and"].append({"price": {"$gte": min_amount}})
        filters["$and"].append({"price": {"$lte": max_amount}})
        
    # L·ªçc theo ch·∫•t li·ªáu d√¢y
    if "d√¢y da" in question_lower:
        if "$and" not in filters: filters["$and"] = []
        filters["$and"].append({"strap_material": "day_da"})
    elif "d√¢y kim lo·∫°i" in question_lower or "th√©p" in question_lower:
        if "$and" not in filters: filters["$and"] = []
        filters["$and"].append({"strap_material": "day_kim_loai"})
    elif "d√¢y v·∫£i" in question_lower:
        if "$and" not in filters: filters["$and"] = []
        filters["$and"].append({"strap_material": "day_vai"})
    elif "d√¢y nh·ª±a" in question_lower or "cao su" in question_lower:
        if "$and" not in filters: filters["$and"] = []
        filters["$and"].append({"strap_material": "day_nhua"})

    # N·∫øu c√≥ nhi·ªÅu h∆°n 1 ƒëi·ªÅu ki·ªán (kh√¥ng ph·∫£i range ƒë√£ x·ª≠ l√Ω), d√πng $and
    final_filters = {}
    conditions = []
    
    # Gom c√°c ƒëi·ªÅu ki·ªán ƒë∆°n l·∫ª
    for k, v in filters.items():
        if k == "$and":
            conditions.extend(v)
        else:
            conditions.append({k: v})
            
    if len(conditions) > 1:
        return {"$and": conditions}
    elif len(conditions) == 1:
        return conditions[0]
    
    return {}


def handle_comparison(question: str, vectordb) -> Optional[str]:
    """X·ª≠ l√Ω c√¢u h·ªèi so s√°nh"""
    question_lower = question.lower()
    if "so s√°nh" not in question_lower:
        return None
        
    # T√¨m 2 s·∫£n ph·∫©m ƒë·ªÉ so s√°nh
    # Pattern: So s√°nh A v·ªõi/v√† B
    compare_match = re.search(r"so s√°nh\s+(.+?)\s+(?:v·ªõi|v√†)\s+(.+)", question_lower)
    if not compare_match:
        return None
        
    prod1 = compare_match.group(1).strip()
    prod2 = compare_match.group(2).strip()
    
    logger.info(f"Comparing {prod1} and {prod2}")
    
    # T√¨m ki·∫øm th√¥ng tin cho t·ª´ng s·∫£n ph·∫©m
    docs1 = vectordb.similarity_search(prod1, k=1)
    docs2 = vectordb.similarity_search(prod2, k=1)
    
    if not docs1 or not docs2:
        return None
        
    context = f"""
TH√îNG TIN S·∫¢N PH·∫®M 1 ({prod1}):
{docs1[0].page_content}

TH√îNG TIN S·∫¢N PH·∫®M 2 ({prod2}):
{docs2[0].page_content}
"""
    return context


def extract_product_info(context: str) -> dict[str, Optional[str]]:
    """Tr√≠ch xu·∫•t th√¥ng tin s·∫£n ph·∫©m t·ª´ context v·ªõi c·∫£i ti·∫øn"""
    info: dict[str, Optional[str]] = {
        "product_name": None,
        "price": None,
        "features": None,
        "brand": None,
        "warranty": None
    }

    # Regex for CSV format (prioritized)
    
    # T√¨m t√™n s·∫£n ph·∫©m
    name_match = re.search(r"T√™n s·∫£n ph·∫©m:\s*(.+?)(?=\n|$)", context, re.IGNORECASE)
    if name_match:
        info["product_name"] = name_match.group(1).strip()
    
    # T√¨m th∆∞∆°ng hi·ªáu
    brand_match = re.search(r"Th∆∞∆°ng hi·ªáu:\s*(.+?)(?=\n|$)", context, re.IGNORECASE)
    if brand_match:
        info["brand"] = brand_match.group(1).strip()
        
    # N·∫øu kh√¥ng t√¨m th·∫•y theo format CSV, th·ª≠ fallback sang regex c≈© (cho ch·∫Øc ch·∫Øn)
    if not info["product_name"]:
        brand_patterns = [
            r"(Casio|Seiko|Citizen|Orient|Tissot|Omega|Rolex)\s+([\w\-]+(?:\s+[\w\-]+)*)",
            r"(\d+\.\s+)?(Casio|Seiko|Citizen|Orient|Tissot|Omega|Rolex)\s+([\w\-]+(?:\s+[\w\-]+)*)"
        ]
        for pattern in brand_patterns:
            brand_matches = re.finditer(pattern, context, re.IGNORECASE)
            for match in brand_matches:
                info["brand"] = match.group(1) if match.group(1) and not match.group(1).isdigit() else match.group(2)
                product_part = match.group(2) if match.group(1) and not match.group(1).isdigit() else match.group(3)
                info["product_name"] = f"{info['brand']} {product_part}"
                break
            if info["product_name"]:
                break

    # T√¨m gi√°
    # Format CSV: Gi√° b√°n: 14.780.000
    price_match_csv = re.search(r"Gi√° b√°n:\s*([\d\.]+)", context, re.IGNORECASE)
    if price_match_csv:
        info["price"] = price_match_csv.group(1).strip()
    else:
        # Fallback regex c≈©
        price_patterns = [
            r"gi√°[:\s]+([\d,\.]+)\s*(VND|ƒë)",
            r"m·ª©c gi√°[:\s]+([\d,\.]+)\s*(VND|ƒë)",
            r"([\d,\.]+)\s*(VND|ƒë)"
        ]
        for pattern in price_patterns:
            price_match = re.search(pattern, context, re.IGNORECASE)
            if price_match:
                info["price"] = price_match.group(1)
                break

    # T√¨m ƒë·∫∑c ƒëi·ªÉm / Th√¥ng s·ªë k·ªπ thu·∫≠t
    # ∆Øu ti√™n Th√¥ng s·ªë k·ªπ thu·∫≠t
    specs_match = re.search(r"Th√¥ng s·ªë k·ªπ thu·∫≠t:\s*(.+?)(?=\n|$)", context, re.IGNORECASE | re.DOTALL)
    if specs_match:
        info["features"] = specs_match.group(1).strip()
    else:
        # Fallback sang M√¥ t·∫£
        desc_match = re.search(r"M√¥ t·∫£:\s*(.+?)(?=\n|$)", context, re.IGNORECASE | re.DOTALL)
        if desc_match:
            info["features"] = desc_match.group(1).strip()
        else:
            features_match = re.search(r"ƒë·∫∑c ƒëi·ªÉm[:\s]+(.+?)(?=\n|$)", context, re.IGNORECASE)
            if features_match:
                info["features"] = features_match.group(1).strip()

    # T√¨m b·∫£o h√†nh
    # Format CSV: B·∫£o h√†nh: ...
    warranty_match_csv = re.search(r"B·∫£o h√†nh:\s*(.+?)(?=\n|$)", context, re.IGNORECASE)
    if warranty_match_csv:
        info["warranty"] = warranty_match_csv.group(1).strip()
    else:
        warranty_match = re.search(r"b·∫£o h√†nh[:\s]+(.+?)(?=\n|$)", context, re.IGNORECASE)
        if warranty_match:
            info["warranty"] = warranty_match.group(1).strip()

    return info


def enhance_context_with_history(session_id: str, current_context: str) -> str:
    """TƒÉng c∆∞·ªùng context v·ªõi l·ªãch s·ª≠ h·ªôi tho·∫°i"""
    if session_id not in conversation_history:
        return current_context
    
    history = conversation_history[session_id]
    if not history:
        return current_context
    
    # L·∫•y 3 c√¢u h·ªèi g·∫ßn nh·∫•t
    recent_history = history[-3:]
    history_context = "\n".join([
        f"Q: {item['question']}\nA: {item['answer'][:200]}..." 
        for item in recent_history
    ])
    
    enhanced_context = f"""
L·ªãch s·ª≠ h·ªôi tho·∫°i g·∫ßn ƒë√¢y:
{history_context}

Th√¥ng tin hi·ªán t·∫°i:
{current_context}
"""
    return enhanced_context


def handle_follow_up(question: str, context: Dict, session_id: str) -> Optional[str]:
    """X·ª≠ l√Ω c√¢u h·ªèi ti·∫øp theo v·ªõi c·∫£i ti·∫øn ng·ªØ c·∫£nh"""
    question = question.lower()
    current_product = context.get("current_product")
    conversation_ctx = context.get("conversation_context", "")

    logger.info(f"Follow-up check - Question: '{question}', Current product: {current_product}")

    if not current_product and not conversation_ctx:
        logger.info("No current product or conversation context found")
        return None

    # X·ª≠ l√Ω ƒë·∫°i t·ª´ (n√≥, c√°i n√†y, s·∫£n ph·∫©m n√†y...)
    pronouns = ["n√≥", "c√°i n√†y", "s·∫£n ph·∫©m n√†y", "ƒë·ªìng h·ªì n√†y", "m·∫´u n√†y", 
                "s·∫£n ph·∫©m ƒë√≥", "ƒë·ªìng h·ªì ƒë√≥", "m·∫´u ƒë√≥", "c√°i ƒë√≥", "th·ª© ƒë√≥"]
    if any(pronoun in question for pronoun in pronouns):
        logger.info(f"Pronoun detected in question: {question}")
        if current_product:
            if "gi√°" in question or "bao nhi√™u ti·ªÅn" in question:
                if context.get("price"):
                    logger.info(f"Returning price info for {current_product}")
                    return f"{current_product} c√≥ gi√° {context['price']} VND."
                logger.info(f"No price info found for {current_product}")
                return f"Xin l·ªói, t√¥i ch∆∞a c√≥ th√¥ng tin gi√° cho {current_product}."

            if "ƒë·∫∑c ƒëi·ªÉm" in question or "t√≠nh nƒÉng" in question:
                if context.get("features"):
                    logger.info(f"Returning features for {current_product}")
                    return f"{current_product} c√≥ ƒë·∫∑c ƒëi·ªÉm: {context['features']}."
                logger.info(f"No features info found for {current_product}")
                return f"Xin l·ªói, t√¥i ch∆∞a c√≥ th√¥ng tin chi ti·∫øt v·ªÅ {current_product}."
                
            if "b·∫£o h√†nh" in question:
                if context.get("warranty"):
                    logger.info(f"Returning warranty info for {current_product}")
                    return f"{current_product} c√≥ {context['warranty']}."
                logger.info(f"No warranty info found for {current_product}")
                return f"Xin l·ªói, t√¥i ch∆∞a c√≥ th√¥ng tin b·∫£o h√†nh cho {current_product}."

            # X·ª≠ l√Ω c√¢u h·ªèi chung v·ªÅ th√¥ng tin s·∫£n ph·∫©m
            if "th√¥ng tin" in question:
                info_parts = []
                if context.get("price"):
                    info_parts.append(f"Gi√°: {context['price']} VND")
                if context.get("features"):
                    info_parts.append(f"ƒê·∫∑c ƒëi·ªÉm: {context['features']}")
                if context.get("warranty"):
                    info_parts.append(f"B·∫£o h√†nh: {context['warranty']}")
                
                if info_parts:
                    logger.info(f"Returning general info for {current_product}")
                    return f"Th√¥ng tin v·ªÅ {current_product}: " + ", ".join(info_parts) + "."
                else:
                    logger.info(f"No detailed info found for {current_product}")
                    return f"Xin l·ªói, t√¥i ch∆∞a c√≥ th√¥ng tin chi ti·∫øt v·ªÅ {current_product}."

            # X·ª≠ l√Ω c√¢u h·ªèi d·ª±a tr√™n ng·ªØ c·∫£nh h·ªôi tho·∫°i
        if conversation_ctx:
            if "so s√°nh" in question or "kh√°c bi·ªát" in question:
                return "D·ª±a tr√™n th√¥ng tin ƒë√£ trao ƒë·ªïi, t√¥i c√≥ th·ªÉ so s√°nh c√°c s·∫£n ph·∫©m cho b·∫°n. B·∫°n mu·ªën so s√°nh ƒëi·ªÉm g√¨ c·ª• th·ªÉ?"
            
            if "khuy·∫øn ngh·ªã" in question or "g·ª£i √Ω" in question:
                return "D·ª±a tr√™n s·ªü th√≠ch b·∫°n ƒë√£ chia s·∫ª, t√¥i c√≥ th·ªÉ ƒë∆∞a ra g·ª£i √Ω ph√π h·ª£p. B·∫°n quan t√¢m ƒë·∫øn m·ª©c gi√° n√†o?"

    logger.info("No follow-up response generated")
    return None


def clean_expired_sessions():
    """D·ªçn d·∫πp c√°c session c≈© v·ªõi c·∫£i ti·∫øn"""
    now = datetime.now()
    expired_keys = []
    
    for key, value in session_contexts.items():
        last_activity = value.get("last_activity")
        if last_activity and now - last_activity > timedelta(hours=2):  # TƒÉng th·ªùi gian l∆∞u tr·ªØ
            expired_keys.append(key)
    
    for key in expired_keys:
        del session_contexts[key]
        if key in conversation_history:
            del conversation_history[key]
        if key in request_counts:
            del request_counts[key]
    
    if expired_keys:
        logger.info(f"Cleaned {len(expired_keys)} expired sessions")


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "active_sessions": len(session_contexts),
        "vector_db_status": "connected" if vectordb else "disconnected"
    }


@app.get("/stats")
async def get_stats():
    """Th·ªëng k√™ s·ª≠ d·ª•ng"""
    return {
        "total_sessions": len(session_contexts),
        "total_conversations": sum(len(conv) for conv in conversation_history.values()),
        "rate_limit": MAX_REQUESTS_PER_MINUTE
    }


def remove_markdown(text: str) -> str:
    """Lo·∫°i b·ªè markdown nh∆∞ **bold**, *italic*, __bold__, _italic_, `code`"""
    text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)
    text = re.sub(r'\*(.*?)\*', r'\1', text)
    text = re.sub(r'__(.*?)__', r'\1', text)
    text = re.sub(r'_(.*?)_', r'\1', text)
    text = re.sub(r'`(.*?)`', r'\1', text)
    return text


@app.post("/chat-stream", response_model=ChatResponse)
async def chat_stream(req: ChatRequest, request: Request):
    """Chat endpoint v·ªõi c·∫£i ti·∫øn to√†n di·ªán"""
    start_time = time.time()
    
    try:
        # Validate input
        question = validate_input(req.question)
        session_id = req.session_id or str(uuid.uuid4())
        
        # Log session information
        logger.info(f"Session ID: {session_id}")
        logger.info(f"Question: '{question}'")
        
        # Rate limiting
        if not check_rate_limit(session_id):
            raise HTTPException(status_code=429, detail="Qu√° nhi·ªÅu y√™u c·∫ßu. Vui l√≤ng th·ª≠ l·∫°i sau 1 ph√∫t.")
        
        # Clean expired sessions
        clean_expired_sessions()
        
        # L·∫•y ng·ªØ c·∫£nh hi·ªán t·∫°i ho·∫∑c t·∫°o m·ªõi
        context = session_contexts.get(session_id, {})
        context["last_activity"] = datetime.now()
        
        # Log current context
        logger.info(f"Current context for session {session_id}: {context}")
        
        # Log request
        logger.info(f"Session {session_id}: {question}")
        
        # X·ª≠ l√Ω c√¢u ch√†o h·ªèi
        greeting_keywords = ["hi", "hello", "ch√†o", "xin ch√†o", "alo"]
        if any(question.lower().strip().startswith(kw) for kw in greeting_keywords) and len(question.split()) <= 4:
             async def greeting_response():
                yield "Ch√†o b·∫°n üëã T√¥i c√≥ th·ªÉ h·ªó tr·ª£ g√¨ cho b·∫°n h√¥m nay?"
             return StreamingResponse(greeting_response(), media_type="text/plain")

        # Ki·ªÉm tra c√¢u h·ªèi kh√¥ng li√™n quan
        if not is_relevant_question(question):
            async def fallback():
                yield "Xin l·ªói, t√¥i ch·ªâ h·ªó tr·ª£ th√¥ng tin v·ªÅ ƒë·ªìng h·ªì. B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ s·∫£n ph·∫©m, gi√° c·∫£, ch√≠nh s√°ch ho·∫∑c th√¥ng tin li√™n h·ªá."
            
            return StreamingResponse(fallback(), media_type="text/plain")

        # X·ª≠ l√Ω y√™u c·∫ßu t∆∞ v·∫•n
        consult_keywords = ["t∆∞ v·∫•n", "gi·ªõi thi·ªáu", "c√°c lo·∫°i", "c√°c h√£ng", "mua ƒë·ªìng h·ªì"]
        
        # Ki·ªÉm tra xem c√≥ t√™n th∆∞∆°ng hi·ªáu n√†o trong c√¢u h·ªèi kh√¥ng
        brands_map = {
            'casio': 'Casio',
            'seiko': 'Seiko',
            'citizen': 'Citizen',
            'orient': 'Orient',
            'doxa': 'Doxa',
            'saga': 'Saga'
        }
        has_brand = any(brand in question.lower() for brand in brands_map)
        
        # Ch·ªâ hi·ªÉn th·ªã danh s√°ch th∆∞∆°ng hi·ªáu n·∫øu c√¢u h·ªèi ng·∫Øn v√† chung chung
        # V√≠ d·ª•: "T∆∞ v·∫•n", "T∆∞ v·∫•n ƒë·ªìng h·ªì", "Gi·ªõi thi·ªáu s·∫£n ph·∫©m"
        is_generic_consult = any(kw in question.lower() for kw in consult_keywords)
        is_short_query = len(question.split()) <= 4
        
        if is_generic_consult and not has_brand and is_short_query:
            async def consult_response():
                yield "Ch√†o b·∫°n, hi·ªán t·∫°i ch√∫ng t√¥i ƒëang kinh doanh c√°c th∆∞∆°ng hi·ªáu ƒë·ªìng h·ªì sau:\n- Casio\n- Seiko\n- Citizen\n- Orient\n- Doxa\n- Saga\n\nB·∫°n mu·ªën t√¨m hi·ªÉu v·ªÅ th∆∞∆°ng hi·ªáu n√†o?"
            return StreamingResponse(consult_response(), media_type="text/plain")

        # X·ª≠ l√Ω khi ng∆∞·ªùi d√πng ch·ªçn th∆∞∆°ng hi·ªáu
        brands_map = {
            'casio': 'Casio',
            'seiko': 'Seiko',
            'citizen': 'Citizen',
            'orient': 'Orient',
            'doxa': 'Doxa',
            'saga': 'Saga'
        }
        
        found_brand = None
        for key, value in brands_map.items():
            if key in question.lower():
                found_brand = value
                break
        
        is_brand_query = False
        # N·∫øu c√¢u h·ªèi ng·∫Øn (ch·ªâ t√™n th∆∞∆°ng hi·ªáu) ho·∫∑c c√≥ √Ω ƒë·ªãnh xem s·∫£n ph·∫©m th∆∞∆°ng hi·ªáu
        # N·∫øu c√¢u h·ªèi ng·∫Øn (ch·ªâ t√™n th∆∞∆°ng hi·ªáu) ho·∫∑c c√≥ √Ω ƒë·ªãnh xem s·∫£n ph·∫©m th∆∞∆°ng hi·ªáu
        if found_brand:
            # Ki·ªÉm tra xem c√≥ ph·∫£i l√† model c·ª• th·ªÉ kh√¥ng
            specific_code = detect_specific_model(question)
            
            general_keywords = ["th∆∞∆°ng hi·ªáu", "s·∫£n ph·∫©m", "c√°c lo·∫°i", "c√°c m·∫´u", "t√¨m hi·ªÉu", "xem", "li·ªát k√™", "danh s√°ch"]
            
            # Ch·ªâ coi l√† brand query n·∫øu KH√îNG ph·∫£i l√† model c·ª• th·ªÉ
            if not specific_code:
                if len(question.split()) <= 4 or any(kw in question.lower() for kw in general_keywords):
                    is_brand_query = True
                    # ƒêi·ªÅu ch·ªânh c√¢u h·ªèi ƒë·ªÉ RAG t√¨m ki·∫øm t·ªët h∆°n
                    question = f"Li·ªát k√™ danh s√°ch c√°c m·∫´u ƒë·ªìng h·ªì {found_brand} n·ªïi b·∫≠t nh·∫•t k√®m gi√° b√°n v√† ƒë·∫∑c ƒëi·ªÉm."
                    logger.info(f"Optimized question for brand listing: {question}")

        # X·ª≠ l√Ω c√¢u h·ªèi ti·∫øp theo d·ª±a tr√™n ng·ªØ c·∫£nh
        follow_up_response = handle_follow_up(question, context, session_id)
        if follow_up_response:
            logger.info(f"Follow-up response for session {session_id}: {follow_up_response}")
            async def respond():
                yield follow_up_response
            
            # L∆∞u v√†o l·ªãch s·ª≠
            if session_id not in conversation_history:
                conversation_history[session_id] = []
            conversation_history[session_id].append({
                "question": question,
                "answer": follow_up_response,
                "timestamp": datetime.now()
            })
            
            return StreamingResponse(respond(), media_type="text/plain")

        # X·ª≠ l√Ω so s√°nh
        comparison_context = handle_comparison(question, vectordb)
        if comparison_context:
            logger.info("Comparison context generated")
            context_text = comparison_context
            relevant_docs = [True] # Dummy to pass check
            
            # C·∫≠p nh·∫≠t prompt cho so s√°nh
            question = f"So s√°nh chi ti·∫øt 2 s·∫£n ph·∫©m d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p: {question}"
        else:
            # Truy v·∫•n vector DB th√¥ng th∆∞·ªùng v·ªõi b·ªô l·ªçc
            filters = extract_search_filters(question)
            logger.info(f"Search filters: {filters}")
            
            search_k = 6 if 'is_brand_query' in locals() and is_brand_query else 3
            
            if filters:
                # N·∫øu c√≥ filter, d√πng filter
                search_result = vectordb.similarity_search_with_score(question, k=search_k, filter=filters)
            else:
                search_result = vectordb.similarity_search_with_score(question, k=search_k)
                
            # Log search results for debugging
            logger.info(f"Search results for '{question}':")
            for doc, score in search_result:
                logger.info(f"  - Score: {score:.4f}, Content: {doc.page_content[:50]}...")

            relevant_docs = [doc for doc, score in search_result if score < 1.8]
            context_text = "\n".join([doc.page_content for doc in relevant_docs]) if relevant_docs else ""
        
        # TƒÉng c∆∞·ªùng context v·ªõi l·ªãch s·ª≠
        enhanced_context = enhance_context_with_history(session_id, context_text)
        
        # Log context ƒë·ªÉ debug
        logger.info(f"Question: '{question}'")
        logger.info(f"Found {len(relevant_docs)} relevant docs")
        logger.info(f"Context: {context_text[:500]}...")
        logger.info(f"Enhanced context: {enhanced_context[:500]}...")

        # C·∫≠p nh·∫≠t ng·ªØ c·∫£nh n·∫øu t√¨m th·∫•y s·∫£n ph·∫©m
        if relevant_docs:
            product_info = extract_product_info(context_text)
            if product_info["product_name"]:
                context.update({
                    "current_product": product_info["product_name"],
                    "brand": product_info["brand"],
                    "price": product_info["price"],
                    "features": product_info["features"],
                    "warranty": product_info["warranty"],
                    "conversation_context": context_text
                })
                logger.info(f"Updated context with product info: {product_info}")

        # L∆∞u ng·ªØ c·∫£nh m·ªõi
        session_contexts[session_id] = context
        logger.info(f"Saved context for session {session_id}: {context}")

        # X·ª≠ l√Ω khi kh√¥ng c√≥ th√¥ng tin ph√π h·ª£p
        # X·ª≠ l√Ω khi kh√¥ng c√≥ th√¥ng tin ph√π h·ª£p t·ª´ search
        if not relevant_docs:
            # Ki·ªÉm tra xem c√≥ th·ªÉ d√πng ng·ªØ c·∫£nh c≈© kh√¥ng
            pronouns = ["n√≥", "c√°i n√†y", "s·∫£n ph·∫©m n√†y", "ƒë·ªìng h·ªì n√†y", "m·∫´u n√†y", "s·∫£n ph·∫©m ƒë√≥", "ƒë·ªìng h·ªì ƒë√≥"]
            has_pronoun = any(p in question.lower() for p in pronouns)
            
            if has_pronoun and context.get("conversation_context"):
                logger.info("Using previous conversation context for follow-up")
                context_text = context["conversation_context"]
                # Proceed to LLM generation with this context
            else:
                # Fallback responses
                if context.get("current_product"):
                    async def no_info_current():
                        yield f"B·∫°n ƒëang h·ªèi v·ªÅ {context['current_product']}. Tuy nhi√™n c√¢u h·ªèi n√†y n·∫±m ngo√†i th√¥ng tin t√¥i c√≥. B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ gi√°, th√¥ng s·ªë ho·∫∑c b·∫£o h√†nh."
                    return StreamingResponse(no_info_current(), media_type="text/plain")
                elif has_pronoun:
                    async def no_info_pronoun():
                        yield "B·∫°n vui l√≤ng n√≥i r√µ t√™n s·∫£n ph·∫©m ƒë·ªìng h·ªì m√† b·∫°n mu·ªën h·ªèi."
                    return StreamingResponse(no_info_pronoun(), media_type="text/plain")
                else:
                    brands_in_data = ["Casio", "Seiko", "Citizen", "Orient"]
                    async def no_info_brand():
                        yield f"Hi·ªán ch√∫ng t√¥i c√≥ ƒë·ªìng h·ªì c√°c th∆∞∆°ng hi·ªáu: {', '.join(brands_in_data)}. Xin l·ªói t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin cho c√¢u h·ªèi c·ªßa b·∫°n."
                    return StreamingResponse(no_info_brand(), media_type="text/plain")

        # Ki·ªÉm tra Model c·ª• th·ªÉ c√≥ trong k·∫øt qu·∫£ kh√¥ng (Ch·ªëng hallucination)
        specific_code = detect_specific_model(question)
        if specific_code and relevant_docs:
            # Ki·ªÉm tra xem code c√≥ trong context_text kh√¥ng
            if specific_code.lower() not in context_text.lower():
                logger.info(f"Specific model {specific_code} not found in retrieved docs")
                async def not_found_response():
                    yield f"Xin l·ªói, hi·ªán t·∫°i shop ch∆∞a c√≥ s·∫µn m·∫´u ƒë·ªìng h·ªì {specific_code} ho·∫∑c th√¥ng tin ch∆∞a ƒë∆∞·ª£c c·∫≠p nh·∫≠t."
                return StreamingResponse(not_found_response(), media_type="text/plain")

        # Ki·ªÉm tra xem context c√≥ ch·ª©a th√¥ng tin ph√π h·ª£p kh√¥ng
        if not context_text.strip():
            async def no_context():
                yield "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan. Vui l√≤ng h·ªèi c·ª• th·ªÉ h∆°n v·ªÅ s·∫£n ph·∫©m, th∆∞∆°ng hi·ªáu ho·∫∑c th√¥ng tin chung."
            return StreamingResponse(no_context(), media_type="text/plain")

        # X·ª≠ l√Ω th√¥ng th∆∞·ªùng v·ªõi LLM
        inputs = {"question": question, "context": enhanced_context}

        async def generate():
            try:
                response_chunks = []
                for chunk in llm.stream(prompt.format(**inputs)):
                    clean_chunk = remove_markdown(chunk)
                    response_chunks.append(clean_chunk)
                    yield clean_chunk
                # L∆∞u v√†o l·ªãch s·ª≠
                full_response = "".join(response_chunks)
                if session_id not in conversation_history:
                    conversation_history[session_id] = []
                conversation_history[session_id].append({
                    "question": question,
                    "answer": full_response,
                    "timestamp": datetime.now()
                })
                # Log response time
                response_time = time.time() - start_time
                logger.info(f"Session {session_id}: Response time {response_time:.2f}s")
            except Exception as e:
                logger.error(f"Error generating response: {e}")
                yield f"ƒê√£ x·∫£y ra l·ªói: {str(e)}"

        response = StreamingResponse(generate(), media_type="text/plain")
        response.set_cookie(
            key="session_id",
            value=session_id,
            max_age=7200,  # 2 gi·ªù
            httponly=True,
            samesite="lax"
        )
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")


if __name__ == "__main__":
    import uvicorn
    
    port = int(os.getenv("PORT", "8000"))
    host = os.getenv("HOST", "0.0.0.0")
    
    logger.info(f"Starting server on {host}:{port}")
    uvicorn.run(app, host=host, port=port)