from fastapi import FastAPI, Request, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from fastapi.security import HTTPBearer
from pydantic import BaseModel, Field
from rag_chain import create_qa_chain
from typing import Dict, Optional, List, Any
import re
import uuid
import logging
import time
from datetime import datetime, timedelta
from collections import defaultdict
import os
import asyncio
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('chatbot.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="Smart Watch Chatbot API",
    description="AI-powered chatbot for watch consultation with context memory",
    version="1.0.0"
)

# Security
security = HTTPBearer(auto_error=False)

# Rate limiting
request_counts = defaultdict(list)
MAX_REQUESTS_PER_MINUTE = int(os.getenv("MAX_REQUESTS_PER_MINUTE", "60"))

# Kh·ªüi t·∫°o QA chain
try:
    qa_chain = create_qa_chain()
    llm = qa_chain["llm"]
    prompt = qa_chain["prompt"]
    vectordb = qa_chain["vectordb"]
    logger.info("QA chain initialized successfully")
except Exception as e:
    logger.error(f"Failed to initialize QA chain: {e}")
    raise

# L∆∞u tr·ªØ ng·ªØ c·∫£nh theo session v·ªõi c·∫£i ti·∫øn
session_contexts: Dict[str, Dict] = {}
conversation_history: Dict[str, List[Dict]] = {}

# C·∫•u h√¨nh CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=os.getenv("ALLOWED_ORIGINS", "http://localhost:5173,http://localhost:8001").split(","),
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class ChatRequest(BaseModel):
    question: str = Field(..., min_length=1, max_length=500, description="C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng")
    session_id: Optional[str] = Field(None, description="ID session ƒë·ªÉ duy tr√¨ ng·ªØ c·∫£nh")
    user_id: Optional[str] = Field(None, description="ID ng∆∞·ªùi d√πng (t√πy ch·ªçn)")


class ChatResponse(BaseModel):
    session_id: str
    response: str
    context_info: Optional[Dict] = None


def validate_input(question: str) -> str:
    """Validate v√† sanitize input"""
    if not question or not question.strip():
        raise HTTPException(status_code=400, detail="C√¢u h·ªèi kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng")
    
    question = question.strip()
    if len(question) > 500:
        raise HTTPException(status_code=400, detail="C√¢u h·ªèi qu√° d√†i (t·ªëi ƒëa 500 k√Ω t·ª±)")
    
    # Basic sanitization
    question = re.sub(r'<script.*?</script>', '', question, flags=re.IGNORECASE)
    return question


def check_rate_limit(session_id: str) -> bool:
    """Ki·ªÉm tra rate limit"""
    now = time.time()
    minute_ago = now - 60
    
    # Clean old requests
    request_counts[session_id] = [req_time for req_time in request_counts[session_id] if req_time > minute_ago]
    
    # Check limit
    if len(request_counts[session_id]) >= MAX_REQUESTS_PER_MINUTE:
        return False
    
    request_counts[session_id].append(now)
    return True


def is_relevant_question(question: str) -> bool:
    """Ki·ªÉm tra c√¢u h·ªèi li√™n quan v·ªõi c·∫£i ti·∫øn"""
    question = question.lower().strip()
    
    # T·ª´ kh√≥a v·ªÅ ƒë·ªìng h·ªì, th∆∞∆°ng hi·ªáu, th√¥ng tin chung
    keywords = [
        'ƒë·ªìng h·ªì', 'watch', 's·∫£n ph·∫©m', 'm·∫´u m√£', 'h√†ng', 'mua', 'b√°n',
        'casio', 'seiko', 'citizen', 'orient', 'tissot', 'omega', 'rolex',
        'gi√°', 'gi√° c·∫£', 'bao nhi√™u ti·ªÅn', 'ƒë·∫∑c ƒëi·ªÉm', 't√≠nh nƒÉng',
        'b·∫£o h√†nh', 'ch√≠nh h√£ng', 'ƒëeo tay', 'th∆∞∆°ng hi·ªáu', 'lo·∫°i',
        'li√™n h·ªá', 'ch√≠nh s√°ch', 'ƒë·ªïi tr·∫£', 'thanh to√°n', 'tr·∫£ g√≥p',
        'ƒë·ªãa ch·ªâ', 's·ªë ƒëi·ªán tho·∫°i', 'h·ªó tr·ª£', 'showroom', 'hotline', 'contact',
        't∆∞ v·∫•n', 'gi·ªõi thi·ªáu', 'so s√°nh', 'khuy·∫øn m√£i', 'gi·∫£m gi√°',
        'giao h√†ng', 'ship', 'v·∫≠n chuy·ªÉn',
        'ch·ªëng n∆∞·ªõc', 'size', 'm√†u', 'k√≠ch th∆∞·ªõc', 'm·∫∑t k√≠nh', 'd√¢y', 'pin', 'c∆°', 'automatic',
        'n√≥', 'c√°i n√†y', 'c√°i ƒë·∫•y', 'em n√≥', 'b√© n√†y'
    ]
    
    brands = ['casio', 'seiko', 'citizen', 'orient', 'tissot', 'omega', 'rolex']
    
    # N·∫øu c√¢u h·ªèi ch·ªâ l√† t√™n th∆∞∆°ng hi·ªáu
    if question in brands:
        return True
    
    # Ki·ªÉm tra t·ª´ kh√≥a
    return any(keyword in question for keyword in keywords)


def detect_specific_model(question: str) -> Optional[str]:
    """Ph√°t hi·ªán xem c√¢u h·ªèi c√≥ ch·ª©a model c·ª• th·ªÉ kh√¥ng"""
    # Pattern: Brand + Code (e.g., Casio MTP-1374L)
    brands = ['casio', 'seiko', 'citizen', 'orient', 'tissot', 'omega', 'rolex', 'doxa', 'saga']
    for brand in brands:
        if brand in question.lower():
            # T√¨m t·ª´ ngay sau brand
            match = re.search(fr"{brand}\s+([A-Za-z0-9\-]+)", question, re.IGNORECASE)
            if match:
                code = match.group(1)
                # N·∫øu code c√≥ s·ªë HO·∫∂C c√≥ d·∫•u g·∫°ch ngang, kh·∫£ nƒÉng cao l√† model
                if any(c.isdigit() for c in code) or "-" in code:
                    return code
    return None


def extract_search_filters(question: str) -> Dict[str, Any]:
    """Tr√≠ch xu·∫•t b·ªô l·ªçc t·ª´ c√¢u h·ªèi"""
    filters = {}
    question_lower = question.lower()
    
    # L·ªçc theo gi·ªõi t√≠nh
    if "nam" in question_lower and "n·ªØ" not in question_lower:
        filters["gender"] = "nam"
    elif "n·ªØ" in question_lower and "nam" not in question_lower:
        filters["gender"] = "nu"
        
    # L·ªçc theo gi√°
    # D∆∞·ªõi X tri·ªáu
    under_match = re.search(r"d∆∞·ªõi\s+(\d+)\s*(tri·ªáu|tr|m)", question_lower)
    if under_match:
        amount = int(under_match.group(1)) * 1000000
        filters["price"] = {"$lt": amount}
        
    # Tr√™n X tri·ªáu
    over_match = re.search(r"(tr√™n|h∆°n)\s+(\d+)\s*(tri·ªáu|tr|m)", question_lower)
    if over_match:
        amount = int(over_match.group(2)) * 1000000
        filters["price"] = {"$gt": amount}
        
    # Kho·∫£ng X-Y tri·ªáu (h·ªó tr·ª£ -, ƒë·∫øn, t·ªõi)
    range_match = re.search(r"t·ª´\s+(\d+)\s*(?:-|ƒë·∫øn|t·ªõi)\s*(\d+)\s*(tri·ªáu|tr|m)", question_lower)
    if range_match:
        min_amount = int(range_match.group(1)) * 1000000
        max_amount = int(range_match.group(2)) * 1000000
        # Chroma c·∫ßn t√°ch ri√™ng c√°c ƒëi·ªÅu ki·ªán
        if "$and" not in filters:
             filters["$and"] = []
        filters["$and"].append({"price": {"$gte": min_amount}})
        filters["$and"].append({"price": {"$lte": max_amount}})
        
    # L·ªçc theo ch·∫•t li·ªáu d√¢y
    if "d√¢y da" in question_lower:
        if "$and" not in filters: filters["$and"] = []
        filters["$and"].append({"strap_material": "day_da"})
    elif "d√¢y kim lo·∫°i" in question_lower or "th√©p" in question_lower:
        if "$and" not in filters: filters["$and"] = []
        filters["$and"].append({"strap_material": "day_kim_loai"})
    elif "d√¢y v·∫£i" in question_lower:
        if "$and" not in filters: filters["$and"] = []
        filters["$and"].append({"strap_material": "day_vai"})
    elif "d√¢y nh·ª±a" in question_lower or "cao su" in question_lower:
        if "$and" not in filters: filters["$and"] = []
        filters["$and"].append({"strap_material": "day_nhua"})

    # L·ªçc theo Phong c√°ch (Style)
    # ChromaDB kh√¥ng h·ªó tr·ª£ $contains cho string metadata m·ªôt c√°ch ƒë∆°n gi·∫£n.
    # Ch√∫ng ta s·∫Ω d·ª±a v√†o vector search ƒë·ªÉ t√¨m ki·∫øm phong c√°ch (th·ªÉ thao, sang tr·ªçng...)
    # v√¨ c√°c t·ª´ kh√≥a n√†y ƒë√£ c√≥ trong page_content.
    pass 

    # N·∫øu c√≥ nhi·ªÅu h∆°n 1 ƒëi·ªÅu ki·ªán (kh√¥ng ph·∫£i range ƒë√£ x·ª≠ l√Ω), d√πng $and
    final_filters = {}
    conditions = []
    
    # Gom c√°c ƒëi·ªÅu ki·ªán ƒë∆°n l·∫ª
    for k, v in filters.items():
        if k == "$and":
            conditions.extend(v)
        else:
            conditions.append({k: v})
            
    if len(conditions) > 1:
        return {"$and": conditions}
    elif len(conditions) == 1:
        return conditions[0]
    
    return {}


def handle_comparison(question: str, vectordb) -> Optional[str]:
    """X·ª≠ l√Ω c√¢u h·ªèi so s√°nh"""
    question_lower = question.lower()
    
    # Pattern 1: So s√°nh A v·ªõi/v√† B
    compare_match = re.search(r"so s√°nh\s+(.+?)\s+(?:v·ªõi|v√†)\s+(.+)", question_lower)
    
    # Pattern 2: Gi·ªØa A v√† B...
    if not compare_match:
        compare_match = re.search(r"gi·ªØa\s+(.+?)\s+(?:v√†|v·ªõi)\s+(.+?)\s+(?:th√¨|m·∫´u n√†o|c√°i n√†o)", question_lower)

    if not compare_match:
        return None
        
    prod1 = compare_match.group(1).strip()
    prod2 = compare_match.group(2).strip()
    
    # Clean up product names (remove "ƒë·ªìng h·ªì", "m·∫´u")
    prod1 = re.sub(r"^(ƒë·ªìng h·ªì|m·∫´u)\s+", "", prod1).strip()
    prod2 = re.sub(r"^(ƒë·ªìng h·ªì|m·∫´u)\s+", "", prod2).strip()

    logger.info(f"Comparing {prod1} and {prod2}")
    
    # T√¨m ki·∫øm th√¥ng tin cho t·ª´ng s·∫£n ph·∫©m
    docs1 = vectordb.similarity_search(prod1, k=1)
    docs2 = vectordb.similarity_search(prod2, k=1)
    
    if not docs1 or not docs2:
        return None
        
    context = f"""
TH√îNG TIN S·∫¢N PH·∫®M 1 ({prod1}):
{docs1[0].page_content}

TH√îNG TIN S·∫¢N PH·∫®M 2 ({prod2}):
{docs2[0].page_content}
"""
    return context


def extract_product_info(context: str) -> dict[str, Optional[str]]:
    """Tr√≠ch xu·∫•t th√¥ng tin s·∫£n ph·∫©m t·ª´ context v·ªõi c·∫£i ti·∫øn"""
    info: dict[str, Optional[str]] = {
        "product_name": None,
        "price": None,
        "features": None,
        "brand": None,
        "warranty": None,
        "stock": None,
        "contact": None
    }

    # Regex for CSV format (prioritized)
    
    # T√¨m t√™n s·∫£n ph·∫©m
    name_match = re.search(r"T√™n s·∫£n ph·∫©m:\s*(.+?)(?=\n|$)", context, re.IGNORECASE)
    if name_match:
        info["product_name"] = name_match.group(1).strip()
    
    # T√¨m th∆∞∆°ng hi·ªáu
    brand_match = re.search(r"Th∆∞∆°ng hi·ªáu:\s*(.+?)(?=\n|$)", context, re.IGNORECASE)
    if brand_match:
        info["brand"] = brand_match.group(1).strip()
        
    # Fallback regex for Name/Brand
    if not info["product_name"]:
        brand_patterns = [
            r"(Casio|Seiko|Citizen|Orient|Tissot|Omega|Rolex)\s+([\w\-]+(?:\s+[\w\-]+)*)",
            r"(\d+\.\s+)?(Casio|Seiko|Citizen|Orient|Tissot|Omega|Rolex)\s+([\w\-]+(?:\s+[\w\-]+)*)"
        ]
        for pattern in brand_patterns:
            brand_matches = re.finditer(pattern, context, re.IGNORECASE)
            for match in brand_matches:
                info["brand"] = match.group(1) if match.group(1) and not match.group(1).isdigit() else match.group(2)
                product_part = match.group(2) if match.group(1) and not match.group(1).isdigit() else match.group(3)
                info["product_name"] = f"{info['brand']} {product_part}"
                break
            if info["product_name"]:
                break

    # T√¨m gi√°
    price_match_csv = re.search(r"Gi√° b√°n:\s*(.+?)(?=\n|$)", context, re.IGNORECASE)
    if price_match_csv:
        raw_price = price_match_csv.group(1).strip()
        # Remove (ƒê√£ bao g·ªìm VAT) for cleaner number parsing if needed, or keep it
        # Let's keep it as is for display, but maybe clean it for calculation if we were doing that.
        # For display: "14780000 (ƒê√£ bao g·ªìm VAT)" is fine.
        info["price"] = raw_price
    else:
        price_patterns = [
            r"gi√°[:\s]+([\d,\.]+)\s*(VND|ƒë)",
            r"m·ª©c gi√°[:\s]+([\d,\.]+)\s*(VND|ƒë)",
            r"([\d,\.]+)\s*(VND|ƒë)"
        ]
        for pattern in price_patterns:
            price_match = re.search(pattern, context, re.IGNORECASE)
            if price_match:
                info["price"] = price_match.group(1)
                break

    # T√¨m s·ªë l∆∞·ª£ng (Stock)
    stock_match = re.search(r"S·ªë l∆∞·ª£ng:\s*(\d+)", context, re.IGNORECASE)
    if stock_match:
        info["stock"] = stock_match.group(1)

    # T√¨m ƒë·∫∑c ƒëi·ªÉm / Th√¥ng s·ªë k·ªπ thu·∫≠t
    specs_match = re.search(r"Th√¥ng s·ªë k·ªπ thu·∫≠t:\s*(.+?)(?=\n|$)", context, re.IGNORECASE | re.DOTALL)
    if specs_match:
        info["features"] = specs_match.group(1).strip()
    else:
        desc_match = re.search(r"M√¥ t·∫£:\s*(.+?)(?=\n|$)", context, re.IGNORECASE | re.DOTALL)
        if desc_match:
            info["features"] = desc_match.group(1).strip()
        else:
            features_match = re.search(r"ƒë·∫∑c ƒëi·ªÉm[:\s]+(.+?)(?=\n|$)", context, re.IGNORECASE)
            if features_match:
                info["features"] = features_match.group(1).strip()

    # T√¨m b·∫£o h√†nh
    warranty_match_csv = re.search(r"B·∫£o h√†nh:\s*(.+?)(?=\n|$)", context, re.IGNORECASE)
    if warranty_match_csv:
        info["warranty"] = warranty_match_csv.group(1).strip()
    else:
        warranty_match = re.search(r"b·∫£o h√†nh[:\s]+(.+?)(?=\n|$)", context, re.IGNORECASE)
        if warranty_match:
            info["warranty"] = warranty_match.group(1).strip()

    # T√¨m th√¥ng tin li√™n h·ªá - C·∫£i thi·ªán regex ƒë·ªÉ b·∫Øt nhi·ªÅu d√≤ng
    contact_match = re.search(r"Th√¥ng tin li√™n h·ªá:[\s\n]*([^\n]+(?:\n[^\n]+)*)", context, re.IGNORECASE)
    if contact_match:
        # Clean up the captured text
        raw_contact = contact_match.group(1).strip()
        # Remove any trailing unrelated text if regex captured too much (unlikely with this pattern but good safety)
        info["contact"] = raw_contact
    else:
        # Fallback regex for email/phone if "Th√¥ng tin li√™n h·ªá:" header is missing or different
        email_match = re.search(r"Email:\s*([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+)", context)
        phone_match = re.search(r"S·ªë ƒëi·ªán tho·∫°i:\s*([\d\.]+)", context)
        contact_parts = []
        if email_match: contact_parts.append(f"Email: {email_match.group(1)}")
        if phone_match: contact_parts.append(f"Hotline: {phone_match.group(1)}")
        
        if contact_parts:
            info["contact"] = ", ".join(contact_parts)
        else:
            info["contact"] = None

    return info


def resolve_coreference(question: str, context: Dict) -> str:
    """Gi·∫£i quy·∫øt tham chi·∫øu (ƒë·∫°i t·ª´, s·ªë th·ª© t·ª±) ƒë·ªÉ l√†m r√µ c√¢u h·ªèi"""
    question_lower = question.lower()
    
    # 1. X·ª≠ l√Ω s·ªë th·ª© t·ª± (c√°i ƒë·∫ßu ti√™n, m·∫´u th·ª© 2...)
    last_list = context.get("last_product_list", [])
    if last_list:
        ordinal_map = {
            "ƒë·∫ßu ti√™n": 0, "th·ª© nh·∫•t": 0, "s·ªë 1": 0,
            "th·ª© hai": 1, "th·ª© 2": 1, "s·ªë 2": 1,
            "th·ª© ba": 2, "th·ª© 3": 2, "s·ªë 3": 2,
            "th·ª© t∆∞": 3, "th·ª© 4": 3, "s·ªë 4": 3,
            "th·ª© nƒÉm": 4, "th·ª© 5": 4, "s·ªë 5": 4
        }
        for key, idx in ordinal_map.items():
            # Ki·ªÉm tra t·ª´ kh√≥a
            if key in question_lower:
                # Y√™u c·∫ßu c√≥ t·ª´ ch·ªâ lo·∫°i ƒëi k√®m ho·∫∑c l√† c√°c t·ª´ ƒë·∫∑c bi·ªát
                triggers = ["c√°i", "m·∫´u", "chi·∫øc", "con", "em", "s·∫£n ph·∫©m"]
                is_valid = any(f"{t} {key}" in question_lower for t in triggers)
                
                if key in ["ƒë·∫ßu ti√™n", "th·ª© nh·∫•t", "cu·ªëi c√πng"]:
                    is_valid = True
                    
                if is_valid and idx < len(last_list):
                    prod_name = last_list[idx]
                    logger.info(f"Resolved ordinal '{key}' to '{prod_name}'")
                    # Thay th·∫ø t·ª´ kh√≥a b·∫±ng t√™n s·∫£n ph·∫©m
                    # V√≠ d·ª•: "C√°i ƒë·∫ßu ti√™n..." -> "ƒê·ªìng h·ªì Casio... c√≥..."
                    # D√πng replace 1 l·∫ßn ƒë·ªÉ tr√°nh thay th·∫ø nh·∫ßm n·∫øu l·∫∑p l·∫°i
                    return question_lower.replace(key, prod_name, 1)

    # 2. X·ª≠ l√Ω ƒë·∫°i t·ª´ (n√≥, c√°i n√†y...)
    pronouns = ["n√≥", "c√°i n√†y", "s·∫£n ph·∫©m n√†y", "ƒë·ªìng h·ªì n√†y", "em n√≥", "b√© n√†y", "chi·∫øc n√†y", "gi√° n√†y", "gi√° ƒë√≥"]
    current_product = context.get("current_product")
    if current_product and any(p in question_lower for p in pronouns):
        logger.info(f"Resolved pronoun to '{current_product}'")
        return f"{current_product} {question}"
        
    return question


def get_conversation_history(session_id: str) -> str:
    """L·∫•y l·ªãch s·ª≠ h·ªôi tho·∫°i ƒë·ªãnh d·∫°ng text"""
    if session_id not in conversation_history:
        return ""
    
    history = conversation_history[session_id]
    if not history:
        return ""
    
    # L·∫•y 5 c√¢u h·ªèi g·∫ßn nh·∫•t ƒë·ªÉ tƒÉng ng·ªØ c·∫£nh
    recent_history = history[-5:]
    history_text = "\n".join([
        f"User: {item['question']}\nAssistant: {item['answer'][:300]}" 
        for item in recent_history
    ])
    
    return history_text


def handle_follow_up(question: str, context: Dict, session_id: str) -> Optional[str]:
    """X·ª≠ l√Ω c√¢u h·ªèi ti·∫øp theo v·ªõi c·∫£i ti·∫øn ng·ªØ c·∫£nh"""
    question = question.lower()
    current_product = context.get("current_product")
    conversation_ctx = context.get("conversation_context", "")

    logger.info(f"Follow-up check - Question: '{question}', Current product: {current_product}")

    # X·ª≠ l√Ω c√¢u h·ªèi v·ªÅ li√™n h·ªá (Global check)
    if any(kw in question for kw in ["li√™n h·ªá", "ƒë·ªãa ch·ªâ", "s·ªë ƒëi·ªán tho·∫°i", "email", "hotline"]):
        if context.get("contact"):
            return f"Th√¥ng tin li√™n h·ªá: {context['contact']}"
        # Fallback if not in context but maybe in general knowledge or footer
        return "B·∫°n c√≥ th·ªÉ li√™n h·ªá v·ªõi ch√∫ng t√¥i qua Hotline: 0905350808 ho·∫∑c Email: topwatch@gmail.com"

    if not current_product and not conversation_ctx:
        logger.info("No current product or conversation context found")
        return None

    # X·ª≠ l√Ω tham chi·∫øu th·ª© t·ª± (m·∫´u ƒë·∫ßu ti√™n, c√°i th·ª© 2...)
    # ƒê√£ ƒë∆∞·ª£c x·ª≠ l√Ω b·ªüi resolve_coreference ƒë·ªÉ rewrite query
    # N√™n ·ªü ƒë√¢y ch√∫ng ta b·ªè qua ƒë·ªÉ query ƒëi xu·ªëng RAG
    pass

    # X·ª≠ l√Ω ƒë·∫°i t·ª´ (n√≥, c√°i n√†y, s·∫£n ph·∫©m n√†y...)
    pronouns = ["n√≥", "c√°i n√†y", "s·∫£n ph·∫©m n√†y", "ƒë·ªìng h·ªì n√†y", "m·∫´u n√†y", 
                "s·∫£n ph·∫©m ƒë√≥", "ƒë·ªìng h·ªì ƒë√≥", "m·∫´u ƒë√≥", "c√°i ƒë√≥", "th·ª© ƒë√≥",
                "c√°i ƒë·∫•y", "em n√≥", "b√© n√†y", "chi·∫øc n√†y", "chi·∫øc ƒë√≥",
                "gi√° n√†y", "gi√° ƒë√≥"] # Added implicit price references
    if any(pronoun in question for pronoun in pronouns):
        logger.info(f"Pronoun detected in question: {question}")
        if current_product:
            # Check VAT (Moved up to prioritize over general price check)
            if "vat" in question or "thu·∫ø" in question:
                return f"Gi√° b√°n c·ªßa {current_product} ƒë√£ bao g·ªìm thu·∫ø VAT."

            if "gi√°" in question or "bao nhi√™u ti·ªÅn" in question:
                if context.get("price"):
                    logger.info(f"Returning price info for {current_product}")
                    return f"{current_product} c√≥ gi√° {context['price']} VND."
                logger.info(f"No price info found for {current_product}")
                return f"Xin l·ªói, t√¥i ch∆∞a c√≥ th√¥ng tin gi√° cho {current_product}."

            if "ƒë·∫∑c ƒëi·ªÉm" in question or "t√≠nh nƒÉng" in question:
                if context.get("features"):
                    logger.info(f"Returning features for {current_product}")
                    return f"{current_product} c√≥ ƒë·∫∑c ƒëi·ªÉm: {context['features']}."
                logger.info(f"No features info found for {current_product}")
                return f"Xin l·ªói, t√¥i ch∆∞a c√≥ th√¥ng tin chi ti·∫øt v·ªÅ {current_product}."
                
            if "b·∫£o h√†nh" in question:
                if context.get("warranty"):
                    logger.info(f"Returning warranty info for {current_product}")
                    return f"{current_product} c√≥ {context['warranty']}."
                logger.info(f"No warranty info found for {current_product}")
                return f"Xin l·ªói, t√¥i ch∆∞a c√≥ th√¥ng tin b·∫£o h√†nh cho {current_product}."
            
            # Check stock
            if "c√≤n h√†ng" in question or "c√≥ s·∫µn" in question or "t·ªìn kho" in question:
                stock = context.get("stock")
                if stock:
                    try:
                        stock_num = int(stock)
                        status = "c√≤n h√†ng" if stock_num > 0 else "ƒë√£ h·∫øt h√†ng"
                        return f"S·∫£n ph·∫©m {current_product} hi·ªán {status} (S·ªë l∆∞·ª£ng: {stock})."
                    except:
                        return f"Hi·ªán t·∫°i {current_product} ƒëang c√≥ s·∫µn t·∫°i c·ª≠a h√†ng."
                return f"S·∫£n ph·∫©m {current_product} hi·ªán ƒëang c√≥ s·∫µn."



            # X·ª≠ l√Ω c√¢u h·ªèi chung v·ªÅ th√¥ng tin s·∫£n ph·∫©m
            if "th√¥ng tin" in question:
                info_parts = []
                if context.get("price"):
                    info_parts.append(f"Gi√°: {context['price']} VND")
                if context.get("features"):
                    info_parts.append(f"ƒê·∫∑c ƒëi·ªÉm: {context['features']}")
                if context.get("warranty"):
                    info_parts.append(f"B·∫£o h√†nh: {context['warranty']}")
                
                if info_parts:
                    logger.info(f"Returning general info for {current_product}")
                    return f"Th√¥ng tin v·ªÅ {current_product}: " + ", ".join(info_parts) + "."
                else:
                    logger.info(f"No detailed info found for {current_product}")
                    return f"Xin l·ªói, t√¥i ch∆∞a c√≥ th√¥ng tin chi ti·∫øt v·ªÅ {current_product}."

            # X·ª≠ l√Ω c√¢u h·ªèi d·ª±a tr√™n ng·ªØ c·∫£nh h·ªôi tho·∫°i
        if conversation_ctx:
            if "so s√°nh" in question or "kh√°c bi·ªát" in question:
                return "D·ª±a tr√™n th√¥ng tin ƒë√£ trao ƒë·ªïi, t√¥i c√≥ th·ªÉ so s√°nh c√°c s·∫£n ph·∫©m cho b·∫°n. B·∫°n mu·ªën so s√°nh ƒëi·ªÉm g√¨ c·ª• th·ªÉ?"
            
            if "khuy·∫øn ngh·ªã" in question or "g·ª£i √Ω" in question:
                return "D·ª±a tr√™n s·ªü th√≠ch b·∫°n ƒë√£ chia s·∫ª, t√¥i c√≥ th·ªÉ ƒë∆∞a ra g·ª£i √Ω ph√π h·ª£p. B·∫°n quan t√¢m ƒë·∫øn m·ª©c gi√° n√†o?"



    logger.info("No follow-up response generated")
    return None


def clean_expired_sessions():
    """D·ªçn d·∫πp c√°c session c≈© v·ªõi c·∫£i ti·∫øn"""
    now = datetime.now()
    expired_keys = []
    
    for key, value in session_contexts.items():
        last_activity = value.get("last_activity")
        if last_activity and now - last_activity > timedelta(hours=2):  # TƒÉng th·ªùi gian l∆∞u tr·ªØ
            expired_keys.append(key)
    
    for key in expired_keys:
        del session_contexts[key]
        if key in conversation_history:
            del conversation_history[key]
        if key in request_counts:
            del request_counts[key]
    
    if expired_keys:
        logger.info(f"Cleaned {len(expired_keys)} expired sessions")


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "active_sessions": len(session_contexts),
        "vector_db_status": "connected" if vectordb else "disconnected"
    }


@app.get("/stats")
async def get_stats():
    """Th·ªëng k√™ s·ª≠ d·ª•ng"""
    return {
        "total_sessions": len(session_contexts),
        "total_conversations": sum(len(conv) for conv in conversation_history.values()),
        "rate_limit": MAX_REQUESTS_PER_MINUTE
    }


def remove_markdown(text: str) -> str:
    """Lo·∫°i b·ªè markdown nh∆∞ **bold**, *italic*, __bold__, _italic_, `code`"""
    text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)
    text = re.sub(r'\*(.*?)\*', r'\1', text)
    text = re.sub(r'__(.*?)__', r'\1', text)
    text = re.sub(r'_(.*?)_', r'\1', text)
    text = re.sub(r'`(.*?)`', r'\1', text)
    return text


@app.post("/chat-stream", response_model=ChatResponse)
async def chat_stream(req: ChatRequest, request: Request):
    """Chat endpoint v·ªõi c·∫£i ti·∫øn to√†n di·ªán"""
    start_time = time.time()
    
    try:
        # Validate input
        question = validate_input(req.question)
        session_id = req.session_id or str(uuid.uuid4())
        
        # Log session information
        logger.info(f"Session ID: {session_id}")
        logger.info(f"Question: '{question}'")
        
        # Rate limiting
        if not check_rate_limit(session_id):
            raise HTTPException(status_code=429, detail="Qu√° nhi·ªÅu y√™u c·∫ßu. Vui l√≤ng th·ª≠ l·∫°i sau 1 ph√∫t.")
        
        # Clean expired sessions
        clean_expired_sessions()
        
        # L·∫•y ng·ªØ c·∫£nh hi·ªán t·∫°i ho·∫∑c t·∫°o m·ªõi
        context = session_contexts.get(session_id, {})
        context["last_activity"] = datetime.now()
        
        # Gi·∫£i quy·∫øt tham chi·∫øu (Coreference Resolution)
        # ƒêi·ªÅu n√†y gi√∫p bi·∫øn "N√≥ gi√° bao nhi√™u" th√†nh "Casio ABC gi√° bao nhi√™u"
        resolved_question = resolve_coreference(question, context)
        is_specific_query = False
        if resolved_question != question:
            logger.info(f"Rewrote question: '{question}' -> '{resolved_question}'")
            question = resolved_question
            is_specific_query = True
            
        original_question = question
        
        # Log current context
        logger.info(f"Current context for session {session_id}: {context}")
        
        # Log request
        logger.info(f"Session {session_id}: {question}")
        
        # X·ª≠ l√Ω c√¢u ch√†o h·ªèi
        greeting_keywords = ["hi", "hello", "ch√†o", "xin ch√†o", "alo"]
        if any(question.lower().strip().startswith(kw) for kw in greeting_keywords) and len(question.split()) <= 4:
             async def greeting_response():
                yield "Ch√†o b·∫°n üëã T√¥i c√≥ th·ªÉ h·ªó tr·ª£ g√¨ cho b·∫°n h√¥m nay?"
             return StreamingResponse(greeting_response(), media_type="text/plain")

        # Ki·ªÉm tra c√¢u h·ªèi kh√¥ng li√™n quan
        if not is_relevant_question(question):
            async def fallback():
                yield "Xin l·ªói, t√¥i ch·ªâ h·ªó tr·ª£ th√¥ng tin v·ªÅ ƒë·ªìng h·ªì. B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ s·∫£n ph·∫©m, gi√° c·∫£, ch√≠nh s√°ch ho·∫∑c th√¥ng tin li√™n h·ªá."
            
            return StreamingResponse(fallback(), media_type="text/plain")

        # X·ª≠ l√Ω y√™u c·∫ßu t∆∞ v·∫•n
        consult_keywords = ["t∆∞ v·∫•n", "gi·ªõi thi·ªáu", "c√°c lo·∫°i", "c√°c h√£ng", "mua ƒë·ªìng h·ªì"]
        
        # Ki·ªÉm tra xem c√≥ t√™n th∆∞∆°ng hi·ªáu n√†o trong c√¢u h·ªèi kh√¥ng
        brands_map = {
            'casio': 'Casio',
            'seiko': 'Seiko',
            'citizen': 'Citizen',
            'orient': 'Orient',
            'doxa': 'Doxa',
            'saga': 'Saga'
        }
        has_brand = any(brand in question.lower() for brand in brands_map)
        
        # Ch·ªâ hi·ªÉn th·ªã danh s√°ch th∆∞∆°ng hi·ªáu n·∫øu c√¢u h·ªèi ng·∫Øn v√† chung chung
        # V√≠ d·ª•: "T∆∞ v·∫•n", "T∆∞ v·∫•n ƒë·ªìng h·ªì", "Gi·ªõi thi·ªáu s·∫£n ph·∫©m"
        is_generic_consult = any(kw in question.lower() for kw in consult_keywords)
        is_short_query = len(question.split()) <= 4
        
        if is_generic_consult and not has_brand and is_short_query:
            async def consult_response():
                yield "Ch√†o b·∫°n, hi·ªán t·∫°i ch√∫ng t√¥i ƒëang kinh doanh c√°c th∆∞∆°ng hi·ªáu ƒë·ªìng h·ªì sau:\n- Casio\n- Seiko\n- Citizen\n- Orient\n- Doxa\n- Saga\n\nB·∫°n mu·ªën t√¨m hi·ªÉu v·ªÅ th∆∞∆°ng hi·ªáu n√†o?"
            return StreamingResponse(consult_response(), media_type="text/plain")

        # X·ª≠ l√Ω khi ng∆∞·ªùi d√πng ch·ªçn th∆∞∆°ng hi·ªáu
        brands_map = {
            'casio': 'Casio',
            'seiko': 'Seiko',
            'citizen': 'Citizen',
            'orient': 'Orient',
            'doxa': 'Doxa',
            'saga': 'Saga'
        }
        
        # Initialize variables to prevent UnboundLocalError
        is_brand_query = False
        relevant_docs = []
        context_text = ""
        
        found_brand = None
        for key, value in brands_map.items():
            if key in question.lower():
                found_brand = value
                break
        
        is_brand_query = False
        # N·∫øu c√¢u h·ªèi ng·∫Øn (ch·ªâ t√™n th∆∞∆°ng hi·ªáu) ho·∫∑c c√≥ √Ω ƒë·ªãnh xem s·∫£n ph·∫©m th∆∞∆°ng hi·ªáu
        # N·∫øu c√¢u h·ªèi ng·∫Øn (ch·ªâ t√™n th∆∞∆°ng hi·ªáu) ho·∫∑c c√≥ √Ω ƒë·ªãnh xem s·∫£n ph·∫©m th∆∞∆°ng hi·ªáu
        if found_brand:
            # Ki·ªÉm tra xem c√≥ ph·∫£i l√† model c·ª• th·ªÉ kh√¥ng
            specific_code = detect_specific_model(question)
            
            general_keywords = ["th∆∞∆°ng hi·ªáu", "s·∫£n ph·∫©m", "c√°c lo·∫°i", "c√°c m·∫´u", "t√¨m hi·ªÉu", "xem", "li·ªát k√™", "danh s√°ch", "t∆∞ v·∫•n"]
            
            # Ch·ªâ coi l√† brand query n·∫øu KH√îNG ph·∫£i l√† model c·ª• th·ªÉ
            if not specific_code:
                if len(question.split()) <= 6 or any(kw in question.lower() for kw in general_keywords):
                    is_brand_query = True
                    # ƒêi·ªÅu ch·ªânh c√¢u h·ªèi ƒë·ªÉ RAG t√¨m ki·∫øm t·ªët h∆°n
                    question = f"Li·ªát k√™ danh s√°ch c√°c m·∫´u ƒë·ªìng h·ªì {found_brand} n·ªïi b·∫≠t nh·∫•t k√®m gi√° b√°n v√† ƒë·∫∑c ƒëi·ªÉm."
                    logger.info(f"Optimized question for brand listing: {question}")

        # X·ª≠ l√Ω c√¢u h·ªèi ti·∫øp theo d·ª±a tr√™n ng·ªØ c·∫£nh
        follow_up_response = handle_follow_up(question, context, session_id)
        if follow_up_response:
            logger.info(f"Follow-up response for session {session_id}: {follow_up_response}")
            async def respond():
                yield follow_up_response
            
            # L∆∞u v√†o l·ªãch s·ª≠
            if session_id not in conversation_history:
                conversation_history[session_id] = []
            conversation_history[session_id].append({
                "question": question,
                "answer": follow_up_response,
                "timestamp": datetime.now()
            })
            
            return StreamingResponse(respond(), media_type="text/plain")

        # X·ª≠ l√Ω ƒë·∫°i t·ª´ ƒë·ªÉ duy tr√¨ ng·ªØ c·∫£nh (Context Retention)
        pronouns = ["n√≥", "c√°i n√†y", "s·∫£n ph·∫©m n√†y", "ƒë·ªìng h·ªì n√†y", "m·∫´u n√†y", 
                    "s·∫£n ph·∫©m ƒë√≥", "ƒë·ªìng h·ªì ƒë√≥", "m·∫´u ƒë√≥", "c√°i ƒë√≥", "th·ª© ƒë√≥",
                    "c√°i ƒë·∫•y", "em n√≥", "b√© n√†y", "chi·∫øc n√†y", "chi·∫øc ƒë√≥"]
        has_pronoun = any(p in question.lower() for p in pronouns)
        forced_context = False
        
        if has_pronoun and context.get("current_product") and context.get("conversation_context"):
            logger.info(f"Pronoun detected ({question}). Using stored context for {context['current_product']}")
            context_text = context["conversation_context"]
            relevant_docs = [True] # Dummy to indicate docs found
            forced_context = True
            
        # X·ª≠ l√Ω so s√°nh (ch·ªâ ch·∫°y n·∫øu kh√¥ng ph·∫£i forced context ho·∫∑c n·∫øu c√¢u h·ªèi c√≥ ch·ª©a "so s√°nh")
        comparison_context = None
        if not forced_context or "so s√°nh" in question.lower():
             comparison_context = handle_comparison(question, vectordb)

        if comparison_context:
            logger.info("Comparison context generated")
            context_text = comparison_context
            relevant_docs = [True] # Dummy to pass check
            
            # C·∫≠p nh·∫≠t prompt cho so s√°nh
            question = f"So s√°nh chi ti·∫øt 2 s·∫£n ph·∫©m d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p: {question}"
        elif not forced_context:
            # Truy v·∫•n vector DB th√¥ng th∆∞·ªùng v·ªõi b·ªô l·ªçc
            filters = extract_search_filters(original_question)
            
            # N·∫øu l√† specific query (ƒë√£ resolve coreference), b·ªè qua filters ƒë·ªÉ t√¨m ki·∫øm ch√≠nh x√°c s·∫£n ph·∫©m
            if 'is_specific_query' in locals() and is_specific_query:
                logger.info("Specific query detected. Ignoring filters.")
                filters = {}
            
            # N·∫øu l√† brand query, th√™m filter th∆∞∆°ng hi·ªáu
            if 'is_brand_query' in locals() and is_brand_query and found_brand:
                brand_filter = {"brand": found_brand.lower()}
                if filters:
                    if "$and" in filters:
                        filters["$and"].append(brand_filter)
                    else:
                        # Wrap existing filter and brand filter in $and
                        filters = {"$and": [filters, brand_filter]}
                else:
                    filters = brand_filter
            
            logger.info(f"Search filters: {filters}")
            
            search_k = 6 if 'is_brand_query' in locals() and is_brand_query else 3
            
            if filters:
                # N·∫øu c√≥ filter, d√πng filter
                search_result = vectordb.similarity_search_with_score(question, k=search_k, filter=filters)
            else:
                search_result = vectordb.similarity_search_with_score(question, k=search_k)
                
            # Log search results for debugging
            logger.info(f"Search results for '{question}':")
            for doc, score in search_result:
                logger.info(f"  - Score: {score:.4f}, Content: {doc.page_content[:50]}...")

            relevant_docs = [doc for doc, score in search_result if score < 1.8]
            
            # N·∫øu l√† specific query (ƒë√£ resolve coreference), l·ªçc relevant_docs ƒë·ªÉ ch·ªâ gi·ªØ l·∫°i ƒë√∫ng s·∫£n ph·∫©m
            # N·∫øu l√† specific query (ƒë√£ resolve coreference), l·ªçc relevant_docs ƒë·ªÉ ch·ªâ gi·ªØ l·∫°i ƒë√∫ng s·∫£n ph·∫©m
            if 'is_specific_query' in locals() and is_specific_query:
                specific_code = detect_specific_model(question)
                if specific_code:
                    # Strict filtering: Only keep docs that contain the specific code
                    filtered_docs = [doc for doc in relevant_docs if specific_code.lower() in doc.page_content.lower()]
                    
                    if filtered_docs:
                        logger.info(f"Filtered docs for specific model {specific_code}: {len(filtered_docs)} docs")
                        relevant_docs = filtered_docs
                    else:
                        # If no docs match the specific code, it's better to return nothing than irrelevant products
                        # However, sometimes the code format might differ slightly.
                        # Let's try to be smart: if we found relevant docs but none match the code, 
                        # it might be a retrieval error or the product isn't there.
                        # To be safe and avoid hallucination, we will limit to the top 1 doc if it has a high score
                        logger.warning(f"Specific model {specific_code} detected but not found in top docs. Limiting to top 1.")
                        if relevant_docs:
                             relevant_docs = [relevant_docs[0]]

            context_text = "\n".join([doc.page_content for doc in relevant_docs]) if relevant_docs else ""
            


        # T·ªêI ∆ØU H√ìA: Tr·∫£ v·ªÅ k·∫øt qu·∫£ tr·ª±c ti·∫øp cho c√¢u h·ªèi li·ªát k√™ (Bypass LLM)
        if is_brand_query and relevant_docs:
            logger.info("Bypassing LLM for brand listing query")
            
            response_lines = [f"D∆∞·ªõi ƒë√¢y l√† c√°c m·∫´u ƒë·ªìng h·ªì {found_brand} n·ªïi b·∫≠t:\n"]
            
            for i, doc in enumerate(relevant_docs):
                # Extract info using metadata (more reliable)
                name = doc.metadata.get('name')
                price = doc.metadata.get('price')
                
                # Fallback to extraction if metadata missing
                if not name or not price:
                    extracted = extract_product_info(doc.page_content)
                    if not name: name = extracted['product_name']
                    if not price: price = extracted['price']
                
                # Format price
                try:
                    price_str = f"{int(price):,.0f}" if price else "Li√™n h·ªá"
                except:
                    price_str = str(price)
                
                # Get features from page_content
                features = "Thi·∫øt k·∫ø sang tr·ªçng, ch√≠nh h√£ng." # Default
                
                # Try to find "M√¥ t·∫£" or "Th√¥ng s·ªë k·ªπ thu·∫≠t"
                desc_match = re.search(r"M√¥ t·∫£:\s*(.+?)(?=\n|$)", doc.page_content, re.IGNORECASE)
                if desc_match:
                    features = desc_match.group(1).strip()
                
                # Truncate features if too long
                if len(features) > 120:
                    features = features[:117] + "..."

                response_lines.append(f"{i+1}. **{name}**")
                response_lines.append(f"   - üí∞ Gi√°: {price_str} VND")
                response_lines.append(f"   - ‚ú® {features}\n")

            final_response = "\n".join(response_lines)
            
            # Save to history
            if session_id not in conversation_history:
                conversation_history[session_id] = []
            conversation_history[session_id].append({
                "question": question,
                "answer": final_response,
                "timestamp": datetime.now()
            })

             # Save product list to context for ordinal reference
            context['last_product_list'] = []
            context_content_list = []
            for doc in relevant_docs:
                 name = doc.metadata.get('name')
                 if not name:
                     extracted = extract_product_info(doc.page_content)
                     name = extracted['product_name']
                 if name:
                     context['last_product_list'].append(name)
                 context_content_list.append(doc.page_content)
            
            # L∆∞u n·ªôi dung v√†o conversation_context ƒë·ªÉ d√πng cho c√¢u h·ªèi sau
            context['conversation_context'] = "\n".join(context_content_list)
            
            # Update session context
            session_contexts[session_id] = context

            async def direct_response():
                for line in response_lines:
                    yield line + "\n"
                    await asyncio.sleep(0.02)
            
            return StreamingResponse(direct_response(), media_type="text/plain")
        
        # L·∫•y l·ªãch s·ª≠ h·ªôi tho·∫°i
        history_text = get_conversation_history(session_id)
        
        # Log context ƒë·ªÉ debug
        logger.info(f"Question: '{question}'")
        logger.info(f"Found {len(relevant_docs)} relevant docs")
        logger.info(f"Context: {context_text[:200]}...")
        logger.info(f"History: {history_text[:200]}...")

        # C·∫≠p nh·∫≠t ng·ªØ c·∫£nh n·∫øu t√¨m th·∫•y s·∫£n ph·∫©m
        if relevant_docs:
            product_info = extract_product_info(context_text)
            if product_info["product_name"]:
                # Logic to decide whether to update current_product
                should_update = True
                
                # Don't update if it's a purely general question without product identifiers
                general_intent_keywords = ["giao h√†ng", "ship", "v·∫≠n chuy·ªÉn", "thanh to√°n", "ƒë·ªãa ch·ªâ", "ƒë·ªïi tr·∫£", "li√™n h·ªá", "shop", "c·ª≠a h√†ng", "online"]
                is_general = any(kw in question.lower() for kw in general_intent_keywords)
                
                # Check if question has brand or specific model code
                brands_map_keys = ['casio', 'seiko', 'citizen', 'orient', 'doxa', 'saga', 'tissot', 'omega', 'rolex']
                has_brand_or_code = any(b in question.lower() for b in brands_map_keys) or detect_specific_model(question)
                
                if is_general and not has_brand_or_code:
                    should_update = False
                    logger.info("General question detected. Preserving previous product context.")

                if should_update:
                    context.update({
                        "current_product": product_info["product_name"],
                        "brand": product_info["brand"],
                        "price": product_info["price"],
                        "features": product_info["features"],
                        "warranty": product_info["warranty"],
                        "stock": product_info.get("stock"),
                        "contact": product_info.get("contact"),
                        "conversation_context": context_text
                    })
                    logger.info(f"Updated context with product info: {product_info}")

        # L∆∞u ng·ªØ c·∫£nh m·ªõi
        session_contexts[session_id] = context
        logger.info(f"Saved context for session {session_id}: {context}")

        # X·ª≠ l√Ω khi kh√¥ng c√≥ th√¥ng tin ph√π h·ª£p
        # X·ª≠ l√Ω khi kh√¥ng c√≥ th√¥ng tin ph√π h·ª£p t·ª´ search
        if not relevant_docs:
            # Ki·ªÉm tra xem c√≥ th·ªÉ d√πng ng·ªØ c·∫£nh c≈© kh√¥ng
            pronouns = ["n√≥", "c√°i n√†y", "s·∫£n ph·∫©m n√†y", "ƒë·ªìng h·ªì n√†y", "m·∫´u n√†y", "s·∫£n ph·∫©m ƒë√≥", "ƒë·ªìng h·ªì ƒë√≥"]
            has_pronoun = any(p in question.lower() for p in pronouns)
            
            if has_pronoun and context.get("conversation_context"):
                logger.info("Using previous conversation context for follow-up")
                context_text = context["conversation_context"]
                # Proceed to LLM generation with this context
            else:
                # Fallback responses
                if context.get("current_product"):
                    async def no_info_current():
                        yield f"B·∫°n ƒëang h·ªèi v·ªÅ {context['current_product']}. Tuy nhi√™n c√¢u h·ªèi n√†y n·∫±m ngo√†i th√¥ng tin t√¥i c√≥. B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ gi√°, th√¥ng s·ªë ho·∫∑c b·∫£o h√†nh."
                    return StreamingResponse(no_info_current(), media_type="text/plain")
                elif has_pronoun:
                    async def no_info_pronoun():
                        yield "B·∫°n vui l√≤ng n√≥i r√µ t√™n s·∫£n ph·∫©m ƒë·ªìng h·ªì m√† b·∫°n mu·ªën h·ªèi."
                    return StreamingResponse(no_info_pronoun(), media_type="text/plain")
                else:
                    brands_in_data = ["Casio", "Seiko", "Citizen", "Orient"]
                    async def no_info_brand():
                        yield f"Hi·ªán ch√∫ng t√¥i c√≥ ƒë·ªìng h·ªì c√°c th∆∞∆°ng hi·ªáu: {', '.join(brands_in_data)}. Xin l·ªói t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin cho c√¢u h·ªèi c·ªßa b·∫°n."
                    return StreamingResponse(no_info_brand(), media_type="text/plain")

        # Ki·ªÉm tra Model c·ª• th·ªÉ c√≥ trong k·∫øt qu·∫£ kh√¥ng (Ch·ªëng hallucination)
        # T·∫°m th·ªùi b·ªè qua check n√†y v√¨ n√≥ qu√° strict v√† g√¢y ra false negative
        # specific_code = detect_specific_model(question)
        # if specific_code and relevant_docs:
        #     # Ki·ªÉm tra xem code c√≥ trong context_text kh√¥ng
        #     if specific_code.lower() not in context_text.lower():
        #         logger.info(f"Specific model {specific_code} not found in retrieved docs")
        #         async def not_found_response():
        #             yield f"Xin l·ªói, hi·ªán t·∫°i shop ch∆∞a c√≥ s·∫µn m·∫´u ƒë·ªìng h·ªì {specific_code} ho·∫∑c th√¥ng tin ch∆∞a ƒë∆∞·ª£c c·∫≠p nh·∫≠t."
        #         return StreamingResponse(not_found_response(), media_type="text/plain")

        # Ki·ªÉm tra xem context c√≥ ch·ª©a th√¥ng tin ph√π h·ª£p kh√¥ng
        if not context_text.strip():
            async def no_context():
                yield "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan. Vui l√≤ng h·ªèi c·ª• th·ªÉ h∆°n v·ªÅ s·∫£n ph·∫©m, th∆∞∆°ng hi·ªáu ho·∫∑c th√¥ng tin chung."
            return StreamingResponse(no_context(), media_type="text/plain")

        # X·ª≠ l√Ω th√¥ng th∆∞·ªùng v·ªõi LLM
        # N·∫øu l√† c√¢u h·ªèi t√¨m ki·∫øm (c√≥ filters) v√† kh√¥ng ph·∫£i l√† follow-up c·ª• th·ªÉ, 
        # ch√∫ng ta n√™n h·∫°n ch·∫ø history ƒë·ªÉ tr√°nh nhi·ªÖu (context pollution).
        # Tuy nhi√™n, n·∫øu l√† c√¢u h·ªèi so s√°nh, history c√≥ th·ªÉ c·∫ßn thi·∫øt.
        
        effective_history = history_text
        if 'filters' in locals() and filters and not comparison_context:
             logger.info("Search query detected with filters. Clearing history to focus on new search results.")
             effective_history = ""

        inputs = {
            "question": question, 
            "context": context_text,
            "history": effective_history
        }

        async def generate():
            try:
                response_chunks = []
                first_chunk = True
                buffer = ""
                in_think_block = False
                
                async for chunk in llm.astream(prompt.format(**inputs)):
                    content = chunk.content if hasattr(chunk, 'content') else str(chunk)
                    
                    if content:
                        buffer += content
                        
                        # Check for <think> tags
                        if "<think>" in buffer:
                            in_think_block = True
                            
                        if in_think_block:
                            if "</think>" in buffer:
                                # Remove the think block and yield the rest
                                buffer = re.sub(r'<think>.*?</think>', '', buffer, flags=re.DOTALL)
                                in_think_block = False
                            else:
                                # Still in think block, wait for closing tag
                                continue
                        
                        # If not in think block, yield content
                        if not in_think_block and buffer:
                            # Skip leading whitespace/newlines to prevent empty bubbles
                            if first_chunk:
                                if not buffer.strip():
                                    buffer = "" # Keep buffering if only whitespace
                                    continue
                                first_chunk = False
                            
                            yield buffer
                            response_chunks.append(buffer)
                            buffer = ""
                # L∆∞u v√†o l·ªãch s·ª≠
                full_response = "".join(response_chunks)
                if session_id not in conversation_history:
                    conversation_history[session_id] = []
                conversation_history[session_id].append({
                    "question": question,
                    "answer": full_response,
                    "timestamp": datetime.now()
                })
                # Log response time
                response_time = time.time() - start_time
                logger.info(f"Session {session_id}: Response time {response_time:.2f}s")
            except Exception as e:
                logger.error(f"Error generating response: {e}")
                yield f"ƒê√£ x·∫£y ra l·ªói: {str(e)}"

        response = StreamingResponse(generate(), media_type="text/plain")
        response.set_cookie(
            key="session_id",
            value=session_id,
            max_age=7200,  # 2 gi·ªù
            httponly=True,
            samesite="lax"
        )
        return response
        
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")


if __name__ == "__main__":
    import uvicorn
    
    port = int(os.getenv("PORT", "8000"))
    host = os.getenv("HOST", "0.0.0.0")
    
    logger.info(f"Starting server on {host}:{port}")
    uvicorn.run(app, host=host, port=port)